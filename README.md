# Dynamic Sign Language Recognition System

## Description

This project aims to develop a system for recognizing sign language gestures using computer vision and machine learning techniques. It leverages Python libraries such as OpenCV, NumPy, Matplotlib, and MediaPipe for image processing and visualization. The trained model can recognize different sign language gestures in real-time using LSTM, and CNN.

## Key Features

- **Image Processing**: Captures and processes video frames using OpenCV.
- **Machine Learning**: Recognizes sign language gestures with a trained model.
- **Visualization**: Uses Matplotlib for result visualization and MediaPipe for hand tracking.
- **Real-time Prediction**: Provides real-time gesture recognition.

## Project Structure

- **Data Handling**: Scripts for handling and preprocessing sign language data.
- **Model Training**: Code for training the machine learning model.
- **Prediction and Visualization**: Functions for making predictions and visualizing results.

## Dependencies

- OpenCV
- NumPy
- Matplotlib
- MediaPipe
- Seaborn
